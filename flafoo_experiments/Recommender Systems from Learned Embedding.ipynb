{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Normalizer , scale\n",
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error \n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MovieLens data.\n",
    "print(\"Downloading movielens data...\")\n",
    "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-100k.zip\", \"movielens.zip\")\n",
    "zip_ref = zipfile.ZipFile('movielens.zip', \"r\")\n",
    "zip_ref.extractall()\n",
    "print(\"Done. Dataset contains:\")\n",
    "print(zip_ref.read('ml-100k/u.info'))\n",
    "\n",
    "# Load each data set (users, movies, and ratings).\n",
    "users_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=users_cols, encoding='latin-1')\n",
    "ratings_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=ratings_cols, encoding='latin-1')\n",
    "\n",
    "# The movies file contains a binary feature for each genre.\n",
    "genre_cols = [\n",
    "    \"genre_unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\",\n",
    "    \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "movies_cols = [\n",
    "    'movie_id', 'title', 'release_date', \"video_release_date\", \"imdb_url\"\n",
    "] + genre_cols\n",
    "movies = pd.read_csv(\n",
    "    'ml-100k/u.item', sep='|', names=movies_cols, encoding='latin-1')\n",
    "\n",
    "# Since the ids start at 1, we shift them to start at 0.\n",
    "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: int(x-1))\n",
    "movies[\"movie_id\"] = movies[\"movie_id\"].apply(lambda x: int(x-1))\n",
    "movies[\"year\"] = movies['release_date'].apply(lambda x: str(x).split('-')[-1])\n",
    "ratings[\"movie_id\"] = ratings[\"movie_id\"].apply(lambda x: int(x-1))\n",
    "ratings[\"user_id\"] = ratings[\"user_id\"].apply(lambda x: int(x-1))\n",
    "ratings[\"rating\"] = ratings[\"rating\"].apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one merged DataFrame containing all the movielens data.\n",
    "movielens = ratings.merge(movies, on='movie_id').merge(users, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movielens.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating = min(movielens[\"rating\"])\n",
    "max_rating = max(movielens[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(movielens, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW_COUNT = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 10\n",
    "NUM_USERS = movielens['user_id'].nunique()\n",
    "NUM_MOVIES = movielens['movie_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_MOVIE_IDS = movielens['movie_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model\n",
    "We are defining a four layer Deep Neural Network. The model has two sub-models inside - `movie_model` and `user_model`. We define them so that once the model is trained, we can extract corresponsing movie or user embedding through these sub-models respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EmbeddingRec(EMBEDDING_SIZE, NUM_MOVIES, NUM_USERS, ROW_COUNT):\n",
    "    movie_input = keras.Input(shape=(1,), name='movie_id')\n",
    "\n",
    "    movie_emb = layers.Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_MOVIES, input_length=ROW_COUNT, name='movie_emb')(movie_input)\n",
    "    movie_vec = layers.Flatten(name='FlattenMovie')(movie_emb)\n",
    "\n",
    "    movie_model = keras.Model(inputs=movie_input, outputs=movie_vec)\n",
    "    \n",
    "    user_input = keras.Input(shape=(1,), name='user_id')\n",
    "\n",
    "    user_emb = layers.Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_USERS, input_length=ROW_COUNT, name='user_emb')(user_input)\n",
    "    user_vec = layers.Flatten(name='FlattenUser')(user_emb)\n",
    "\n",
    "    user_model = keras.Model(inputs=user_input, outputs=user_vec)\n",
    "    \n",
    "    merged = layers.Dot(name = 'dot_product', normalize = True, axes = 2)([movie_emb, user_emb])\n",
    "    merged_dropout = layers.Dropout(0.2)(merged)\n",
    "    \n",
    "    \n",
    "    dense_1 = layers.Dense(70,name='FullyConnected-1')(merged)\n",
    "    dropout_1 = layers.Dropout(0.2,name='Dropout_1')(dense_1)\n",
    "\n",
    "    dense_2 = layers.Dense(50,name='FullyConnected-2')(dropout_1)\n",
    "    dropout_2 = layers.Dropout(0.2,name='Dropout_2')(dense_2)\n",
    "\n",
    "    dense_3 = keras.layers.Dense(20,name='FullyConnected-3')(dropout_2)\n",
    "    dropout_3 = keras.layers.Dropout(0.2,name='Dropout_3')(dense_3)\n",
    "\n",
    "    dense_4 = keras.layers.Dense(10,name='FullyConnected-4', activation='relu')(dropout_3)\n",
    "\n",
    "    result = layers.Dense(1, name='result', activation=\"relu\") (dense_4)\n",
    "\n",
    "    adam = keras.optimizers.Adam(lr=0.001)\n",
    "    model = keras.Model([movie_input, user_input], result)\n",
    "    model.compile(optimizer=adam,loss= 'mean_absolute_error')\n",
    "    return model, movie_model, user_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, movie_model, user_model = EmbeddingRec(EMBEDDING_SIZE, NUM_MOVIES, NUM_USERS, ROW_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping('val_loss', patience=10),\n",
    "             keras.callbacks.ModelCheckpoint('besttest.h5', save_best_only=True)]\n",
    "\n",
    "history = model.fit([train.movie_id, train.user_id],train.rating, batch_size=100,\n",
    "                              epochs =50, validation_data = ([test.movie_id, test.user_id],test.rating),\n",
    "                              verbose = 1, \n",
    "                              callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()[0]\n",
    "\n",
    "# Creating a dictionary to store the embeddings in. The key is a unique word and \n",
    "# the value is the numeric vector\n",
    "# embedding_dict = {}\n",
    "# for word in words: \n",
    "#     embedding_dict.update({\n",
    "#         word: weights[unique_word_dict.get(word)]\n",
    "#         })\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout a sample user embedding\n",
    "user_model.predict([np.array([10]), np.array([3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'] , 'g')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend(['train'], loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we interpret this model?\n",
    "\n",
    "We observe that the training loss decreases over epochs which means that the training is converging to an optimal point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_USER_ID = 200\n",
    "TEST_MOVIE_ID = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Movie embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_EMBEDDING_LIST = []\n",
    "MOVIE_EMBED_MAP = collections.defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(UNIQUE_MOVIE_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _id in UNIQUE_MOVIE_IDS:\n",
    "    emb = movie_model.predict(np.array([_id]))\n",
    "    val = list(emb.reshape(1,-1))[0]\n",
    "    print(\"_id\", _id)\n",
    "    print(\"val \", val)\n",
    "    MOVIE_EMBEDDING_LIST.insert(_id, val)\n",
    "    MOVIE_EMBED_MAP[_id] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MOVIE_EMBEDDING_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Embeddings\n",
    "How do we know that these embeddings are correct? One way to verify them is to plot those embeddings. Once you plot, you will see that movies with a similar rating (as the rating was our target) are close by in the embedding space. Let's have a look.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model, MOVIE_EMBEDDING_LIST, size = NUM_MOVIES):\n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(MOVIE_EMBEDDING_LIST[:size])\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "    labels = list(range(0,size))\n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],xy=(x[i], y[i]),xytext=(5, 2),textcoords='offset points',ha='right',va='bottom')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(model, MOVIE_EMBEDDING_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure is a little hard to visualize. So I am going to plot the 1st 300 movie embeddings to check if I can get a clearer picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(model, MOVIE_EMBEDDING_LIST, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the average rating for movie id `53`, `66` and `9` looks like. From the above figure, movie id `53` and `66` should have similar rating than movie id `9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(movielens.loc[movielens['movie_id'] == 53, 'rating'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(movielens.loc[movielens['movie_id'] == 66, 'rating'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(movielens.loc[movielens['movie_id'] == 9, 'rating'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top-K Candidates using K-Nearest Neighbor\n",
    "\n",
    "Now that we have the embeddings, we can apply the nearest neighbor algorithm to recommend movies to users. We can get `user_embedding` from the `user_id` and find out what are the movies that are close to the `user_embedding` in the embedding space. We use K-Nearest Neighbor algorithm for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_label = UNIQUE_MOVIE_IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=11)\n",
    "clf.fit(MOVIE_EMBEDDING_LIST, knn_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MOVIE_EMBEDDING_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(embedding):\n",
    "    distances, indices = clf.kneighbors(embedding.reshape(1, -1),  n_neighbors=10)\n",
    "    indices = indices.reshape(10,1)\n",
    "    df_indices = pd.DataFrame(indices, columns = ['movie_id'])\n",
    "    return df_indices.merge(movies,on='movie_id',how='inner',suffixes=['_u', '_m'])['title']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_USER_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding = user_model.predict([TEST_USER_ID]).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_movies(user_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
