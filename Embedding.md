## How I created my own Word Embedding

I am trying to build a search engine. I dream to make it very very intelligent.Anyone can use it and train it using a corpus and it will build it's own index and query oprimizer and other components required in . a search and will search on unstructured data. It would be far from anything like just a keyword based search. My search tool will thrive on unstructured data and it will be like a little google sitting on your own machine and will be an intelligent finder and optimizer. 

Probably I would like o build a tool like notion + Hyper-graph + deep learning based serach and I might 
integrate with slack.

The first phase of this deep learning based search is to build a synonym based query. So the query optimizer would be able to pick up synonyms, abbreviations similar and closer word etc. Now how am I going to do this?

My plan is to build a a word embedding based on arxiv data and see how it can search abbreviations.
Firstly I would try to explain what is a word embedding and how does that work.
